% Do not modify these
\documentclass[fleqn,10pt]{wlscirep}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}



% -- Insert any custom LaTeX packages here --

% \package{natbib} % <-- Required for the Chicago citation style
% \package{apacite} % <-- Required for the APA citation style
% If you decide to use one of the styles above, remember to change the \bibliographystyle{} at the bottom of the document too!

\usepackage{listings} % <-- Required if you want to display program source code in your paper.
\usepackage{xcolor}
 
 
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 
% -- End of custom LaTeX packages --
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
    }
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}
\urlstyle{same}

% Fill in your title
\title{Exploring Science Fiction \& Fantasy Q/A}

% Do not modify the author tag below, just let it be blank
\author{}
\twocolumn
% Fill in assignment abstract
\begin{abstract}
In this assignment we parsed a dataset, in the form of XMLs, through a Hadoop- and pig apache. We learned how to write MapReduce jobs and Pig scripts, and how effective it is on our dataset based on XML files from science fiction and Fantasy stack exchange. 

\end{abstract}


% Do not modify the following two lines
\lstset{style=mystyle}
\begin{document}
\include{cover}




% Insert data for the hand-in's cover page
\makecoverpage{
	master_of 		 = \par{Applied Computer Science},  % Use either: Applied Computer Science | Human-Computer Interaction
	assignment_title = \par{Exploring Science Fiction and Fantasy},  % Title of your assignment
	course_code    	 = \par{Fill in},  % Course code (ex. MA110)
	course_name      = \par{Big Data},  % Course name (ex. Systems Development)
	due_date		 = \par{24. February},  % Due date
	student_name     = \par{-},  % Your name (or names, if group – separate names with ; semicolon)
	student_number   = \par{865317, 866354},  % Your student ID number (or numbers, if group – separate ID numbers with ; semicolon)
	group_size		 = 2, % Number of group members (used for the declaration text)
}


% Do not modify the following two lines
\flushbottom
\maketitle


% --INTRODUCTION--
\section{Introduction}
This report is of a structure where each task is independent and separately reported, frequently referring to each other due to their similarity. Each contains our assumptions about what the task is asking for, implementation, and any notes/reflections if necessary, opting to add notes/reflection more than necessary rather than less than necessary.\\

We chose to work together because both of us have python background, choosing python as main programming language. We explored a Science Fiction \& Fantasy Q\&A StackExchange dataset based in XML-files as given from \url{archive.org/download/stackexchange/scifi.stackexchange.com.7z} (accessed 17.02.2020) through Hadoop and Pig.\\
Hadoop is used to store and process big data, it has enormous processing power potential and has the ability to handle virtually any number of tasks and jobs. Hadoop provides a framework which allow users to write and test distributed systems and does not rely on hardware to provide fault tolerance, making it less apt for our small-scale applications, yet we use it for the experience. Pig is a MapReduce abstraction, working on Hadoop methods, that we use in some tasks due to its efficiency. We have elected to use both pig-scripts and pure MapReduce for very similar tasks (see 2c and 2d) to both show our ability to employ both methods and get experience with the two methods.

\section{Main functions}
The datasets consists only XML files which, being of a document-oriented database, is structured into attributes attributed to each element of the file. Being oriented towards use in HTML, i.e. a website, the attributes contain ascii characters, punctuation, numbers and HTML tags that we don't want to be there. For this we designed the function cleanBody, meant to clean the text gained from the XML-documents. Additionally a function to parse the XML files was required, for which we created XmlParser. Lastly, we created a general function that would perform the duties of putting out the results of the mapper function; mapper\_core. This section explains their implementations, details the modules imported and describes the bash-script used to run our python-scripts: 


\subsection{cleanBody}
The cleanBody function formats strings to be parseable by python interpreters. The function removes case sensitivity, ascii characters, HTML formatting, and treats anything separated by blanked space or / as separated words. This simple implementation of text formatting will affect the results of some tasks. For instances the name "Jens-Petter" will be interpreted as the word "jenspetter" and the filepath /documents/folder/file.extension will be interpreted as the words "documents", "folder" and "fileextension". \\
The function takes a string as input, formats it and outputs a list of all the words split by the string.split(" ") function.
It uses the sub-function of the open source re module to remove HTML-tags and ascii function that is inherent starting with in python 3 to convert all characters to parse-able ascii text. The symbols in ignore\_char, which are characters we are not considering is defined by the builtin string functions string.punctuation and string.digits.
\begin{lstlisting}[language=Python, caption=cleanBody function]
def cleanBody(body):
    body = body.lower()
    body = ascii(body)
    body = sub("<.+?>","",body)
    body = body.replace("/", " ")
    body = body.strip()

    for i in ignore_char:
        	body = body.replace(i, "")

    body = body.split(" ")

    return body
\end{lstlisting}
\subsection{Mapper Core}
mapper\_core is the core of the mapper function; it prints out the relevant data in a format parseable by Hadoop. It functions through three modes, as determined by the parameter mode: "single", "double", and "triple".

\begin{itemize}
  \item Single: Assumes input "words" is a list of words to print. Prints word in words as (word, 1). Ignores empty strings and spaces.
  \item Double: Assumes input "words" is two nested lists to print. Prints word, count in words as (word, count). Ignores empty strings and spaces.
  \item Triple: Assumes input "words" is three nested lists to print. Prints id, score, title in words as (id, score, title). does not ignore empty strings and spaces.
\end{itemize}

\begin{lstlisting}[language=Python, caption=mapper\_core function]
def mapper_core(words, mode="single"):
    if mode == "single":
        for word in words:
            if word not in ["", " "]:
              print("%s %s" %(word,1)) #Emit the word

    elif mode == "double":
        in1, in2 = words
        for word, count in zip(in1,in2):
            if word not in ["", " "]:
                print("%s %s" %(word,count)) #emit the words

    elif mode == "triple":
        in1, in2,in3  = words
        for id, score, title in zip(in1,in2,in3):
            print("%s %s %s" %(id,score, title)) #emit the words

\end{lstlisting}

\subsection{xmlparser}
The xmlparser function parses an xml using the open-source xml.etree.ElementTree. For normal use it uses sys.stdin as input, but for debugging purposes it also contains a clause that lets it accept a string (see the isinstance(infile, str) check) as a path to the location of an XML-file.\\
Although parsing an entire XML-file takes up significant memory, this method fits our dataset. It has been separated out as a function so it may be easily replaced by other methods more fit for large files. The input for this function is a XML-file and the output is a parsed XML-file.

\begin{lstlisting}[language=Python, caption=xmlparser function]
def xmlparser(infile):
    if not isinstance(infile, str):
        infile = infile.detach()
    mytree = ET.parse(infile)
    myroot = mytree.getroot()
    return myroot
\end{lstlisting}

\subsection{Import sys}
The sys module is an open-source, built in python function that allows us to add to the module search path with sys.path.append(\'../\'), enabling finding ProjectFunctions in a parallel folder, and read in the input for our mapper function and reduce function using sys.stdin.
\begin{lstlisting}[language=Python, caption=Import for sys]
import sys
sys.path.append(\'../\') #allows access functions in parallel folder
import ProjectFunctions.functions as proj
\end{lstlisting}



\subsection{Import xml.etree.ElementTree}
ElementTree is a part of the xml open-source library. XML is an inherently hierarchical data format, being document-oriented, and is naturally represented using a tree-like structure. By using the library ElementTree will represent the XML document as a tree, and elements of the tree is represented as single nodes. 
\begin{lstlisting}[language=Python, caption=Import for ElementTree]
import xml.etree.ElementTree as ET
\end{lstlisting}

\subsection{Import re.sub}
re.sub is an open-source module we use in cleanBody to remove HTML-tags by removing anything that appears between two chevrons.
\begin{lstlisting}[language=Python, caption=Import for re.sub]
from re import sub
\end{lstlisting}

\subsection{Bash-script}
As an example of files being run, this bash-script that was used while testing out scripts is provided. It was used on a windows PC, meaning scripts had to be converted to unix code. It automatically names, cleans, and saves outputs locally. In this example task 4 index is being run. Other examples are 2c using task=2c and taskname=TopMiners and xmlsource=users.
\lstinputlisting[title=bash-script for a windows-based environment]{runscript.sh}





% Do not modify this last lines
\end{document}


































